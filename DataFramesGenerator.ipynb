{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This notebook is oriented to the creation of an pandas dataframe builded from GTZAN Music Genre Dataset:\n",
    "This features are: cqt, rmse, energy, mfccs, chromagram and spectral contrast\n",
    "This notebook is currently in development phase, so contains a considerably quantity of test code\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import librosa, librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n",
    "import pydub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iniciando...\n",
      "Ha salio bien\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "This block is aim to read original GTZAN Dataset\n",
    "\"\"\"\n",
    "\n",
    "# Reading Audio Data from GTZAN\n",
    "\n",
    "print('iniciando...')\n",
    "\n",
    "audios_blues = [\n",
    "    librosa.load(p)[0] for p in Path().glob('Datasets/GTZAN_GENRE_COLLECTION/genres/blues/blues.000*.au')\n",
    "]\n",
    "\n",
    "audios_classical = [\n",
    "    librosa.load(p)[0] for p in Path().glob('Datasets/GTZAN_GENRE_COLLECTION/genres/classical/classical.000*.au')\n",
    "]\n",
    "\n",
    "audios_country = [\n",
    "    librosa.load(p)[0] for p in Path().glob('Datasets/GTZAN_GENRE_COLLECTION/genres/country/country.000*.au')\n",
    "]\n",
    "\n",
    "audios_disco = [\n",
    "    librosa.load(p)[0] for p in Path().glob('Datasets/GTZAN_GENRE_COLLECTION/genres/disco/disco.000*.au')\n",
    "]\n",
    "\n",
    "audios_hiphop = [\n",
    "    librosa.load(p)[0] for p in Path().glob('Datasets/GTZAN_GENRE_COLLECTION/genres/hiphop/hiphop.000*.au')\n",
    "]\n",
    "\n",
    "audios_jazz = [\n",
    "    librosa.load(p)[0] for p in Path().glob('Datasets/GTZAN_GENRE_COLLECTION/genres/jazz/jazz.000*.au')\n",
    "]\n",
    "\n",
    "audios_metal = [\n",
    "    librosa.load(p)[0] for p in Path().glob('Datasets/GTZAN_GENRE_COLLECTION/genres/metal/metal.000*.au')\n",
    "]\n",
    "\n",
    "audios_pop = [\n",
    "    librosa.load(p)[0] for p in Path().glob('Datasets/GTZAN_GENRE_COLLECTION/genres/pop/pop.000*.au')\n",
    "]\n",
    "\n",
    "audios_reggae = [\n",
    "    librosa.load(p)[0] for p in Path().glob('Datasets/GTZAN_GENRE_COLLECTION/genres/reggae/reggae.000*.au')\n",
    "]\n",
    "\n",
    "audios_rock = [\n",
    "    librosa.load(p)[0] for p in Path().glob('Datasets/GTZAN_GENRE_COLLECTION/genres/rock/rock.000*.au')\n",
    "]\n",
    "\n",
    "\n",
    "print('Ha salio bien')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iniciando...\n",
      "Ha salio bien\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "This block is aim to read slice in 10 GTZAN Dataset\n",
    "\"\"\"\n",
    "\n",
    "# Reading Audio Data\n",
    "\n",
    "print('iniciando...')\n",
    "\n",
    "audios_blues = [\n",
    "        librosa.load(p)[0] for p in Path().glob('Datasets/GTZAN_GENRE_COLLECTION/audio3sec/blues/blues0*')\n",
    "]\n",
    "\n",
    "audios_classical = [\n",
    "    librosa.load(p)[0] for p in Path().glob('Datasets/GTZAN_GENRE_COLLECTION/audio3sec/classical/classical0*')\n",
    "]\n",
    "\n",
    "audios_country = [\n",
    "    librosa.load(p)[0] for p in Path().glob('Datasets/GTZAN_GENRE_COLLECTION/audio3sec/country/country0*')\n",
    "]\n",
    "\n",
    "audios_disco = [\n",
    "    librosa.load(p)[0] for p in Path().glob('Datasets/GTZAN_GENRE_COLLECTION/audio3sec/disco/disco0*')\n",
    "]\n",
    "\n",
    "audios_hiphop = [\n",
    "    librosa.load(p)[0] for p in Path().glob('Datasets/GTZAN_GENRE_COLLECTION/audio3sec/hiphop/hiphop0*')\n",
    "]\n",
    "\n",
    "audios_jazz = [\n",
    "    librosa.load(p)[0] for p in Path().glob('Datasets/GTZAN_GENRE_COLLECTION/audio3sec/jazz/jazz0*')\n",
    "]\n",
    "\n",
    "audios_metal = [\n",
    "    librosa.load(p)[0] for p in Path().glob('Datasets/GTZAN_GENRE_COLLECTION/audio3sec/metal/metal0*')\n",
    "]\n",
    "\n",
    "audios_pop = [\n",
    "    librosa.load(p)[0] for p in Path().glob('Datasets/GTZAN_GENRE_COLLECTION/audio3sec/pop/pop0*')\n",
    "]\n",
    "\n",
    "audios_reggae = [\n",
    "    librosa.load(p)[0] for p in Path().glob('Datasets/GTZAN_GENRE_COLLECTION/audio3sec/reggae/reggae0*')\n",
    "]\n",
    "\n",
    "audios_rock = [\n",
    "    librosa.load(p)[0] for p in Path().glob('Datasets/GTZAN_GENRE_COLLECTION/audio3sec/rock/rock0*')\n",
    "]\n",
    "\n",
    "print('Ha salio bien')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iniciando...\n",
      "Ha salio bien\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This block is aim to read original ISMIR04 Dataset\n",
    "\"\"\"\n",
    "\n",
    "# Reading Audio Data from ISMIR04\n",
    "\n",
    "print('iniciando...')\n",
    "\n",
    "audios_classical = [\n",
    "    librosa.load(p)[0] for p in Path().glob('Datasets/ismir04_genre/audio/evaluation/classical/classical0*')\n",
    "]\n",
    "\n",
    "audios_electronic = [\n",
    "    librosa.load(p)[0] for p in Path().glob('Datasets/ismir04_genre/audio/evaluation/electronic/electronic0*')\n",
    "]\n",
    "\n",
    "audios_jazz = [\n",
    "    librosa.load(p)[0] for p in Path().glob('Datasets/ismir04_genre/audio/evaluation/jazz/jazz0*')\n",
    "]\n",
    "\n",
    "audios_metal = [\n",
    "    librosa.load(p)[0] for p in Path().glob('Datasets/ismir04_genre/audio/evaluation/metal/metal0*')\n",
    "]\n",
    "\n",
    "audios_pop = [\n",
    "    librosa.load(p)[0] for p in Path().glob('Datasets/ismir04_genre/audio/evaluation/pop/pop0*')\n",
    "]\n",
    "\n",
    "audios_punk = [\n",
    "    librosa.load(p)[0] for p in Path().glob('Datasets/ismir04_genre/audio/evaluation/punk/punk0*')\n",
    "]\n",
    "\n",
    "audios_rock = [\n",
    "    librosa.load(p)[0] for p in Path().glob('Datasets/ismir04_genre/audio/evaluation/rock/rock0*')\n",
    "]\n",
    "\n",
    "audios_world = [\n",
    "    librosa.load(p)[0] for p in Path().glob('Datasets/ismir04_genre/audio/evaluation/world/world0*')\n",
    "]\n",
    "\n",
    "print('Ha salio bien')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funtions to extracting features \n",
    "\n",
    "import sklearn\n",
    "import librosa\n",
    "\n",
    "class FeaturesExtractor():\n",
    "    \"\"\"\n",
    "    Class that contains several methods to extract means audio features from an audioArray\n",
    "    If user dont use specific parameters class use default values\n",
    "    This class make use of sklean and librosa packages\n",
    "    \n",
    "    feature_to_extract = possible values = \"mean\" or \"var\"\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, hop_length=1024, frame_length=2048, sr=22050, fmin=36, n_bins= 72, lag_seconds=4, feature_to_extract=\"mean\"):\n",
    "        self.hop_length = hop_length\n",
    "        self.frame_length = frame_length\n",
    "        self.sr = sr\n",
    "        self.fmin = fmin\n",
    "        self.n_bins = n_bins\n",
    "        self.lag_seconds = lag_seconds\n",
    "        self.feature_to_extract = feature_to_extract\n",
    "    \n",
    "    def get_short_time_energy(self, audio_array, sr=None, hop_length=None, frame_length=None):\n",
    "        if sr is None: sr=self.sr\n",
    "        if hop_length is None: hop_length=self.hop_length\n",
    "        if frame_length is None: frame_length=self.frame_length\n",
    "        \n",
    "        librosa.get_duration(audio_array, sr)\n",
    "        energy = np.array([\n",
    "            sum(abs(audio_array[i:i+frame_length]**2))\n",
    "            for i in range(0, len(audio_array), hop_length)\n",
    "        ])\n",
    "        \n",
    "        if self.feature_to_extract is \"mean\": return energy.mean(axis=0)\n",
    "        elif self.feature_to_extract is \"var\": return energy.var()\n",
    "        else: return energy\n",
    "\n",
    "    def get_rmse(self, audio_array, sr=None, hop_length=None, frame_length=None):\n",
    "        if sr is None: sr=self.sr\n",
    "        if hop_length is None: hop_length=self.hop_length\n",
    "        if frame_length is None: frame_length=self.frame_length\n",
    "        \n",
    "        rmse = librosa.feature.rms(audio_array, frame_length=frame_length, hop_length=hop_length, center=True)\n",
    "        rmse = rmse[0]\n",
    "        if self.feature_to_extract is \"mean\": return rmse.mean(axis=0)\n",
    "        elif self.feature_to_extract is \"var\": return rmse.var()\n",
    "        else: return rmse\n",
    "\n",
    "\n",
    "    def get_zcr(self, audio_array):\n",
    "#       we add a little constant for avoid silence near 0\n",
    "        zero_crossings = librosa.zero_crossings(audio_array + 0.0001)\n",
    "        zero_crossings = sum(zero_crossings)\n",
    "        return zero_crossings\n",
    "#         return zero_crossings.mean()\n",
    "\n",
    "    def get_mfccs_means(self, audio_array, sr=None, number_mfccs=13):\n",
    "        if sr is None: sr=self.sr\n",
    "            \n",
    "        mfccs = librosa.feature.mfcc(audio_array, sr, n_mfcc=number_mfccs)\n",
    "        mfccs_means = np.arange(number_mfccs)\n",
    "        for i in  range(0, len(mfccs)):\n",
    "            if self.feature_to_extract is \"mean\": mfccs_means[i] = mfccs[i].mean(axis=0).mean()\n",
    "            elif self.feature_to_extract is \"var\": mfccs_means[i] = mfccs[i].var()\n",
    "            else: mfccs_means[i] = mfccs[i].mean(axis=0).mean()\n",
    "            \n",
    "        \n",
    "        return mfccs_means\n",
    "    \n",
    "#         mfccs = sklearn.preprocessing.scale(mfccs, axis=1)\n",
    "#         print()\n",
    "#         print (mfccs.mean(axis=1))\n",
    "#         print (mfccs.var(axis=1))\n",
    "#         librosa.display.specshow(mfccs, sr=sr, x_axis='time')\n",
    "    \n",
    "    def get_cqt(self, audio_array, sr=None, hop_length=None, fmin=None, n_bins=None):\n",
    "        if sr is None: sr=self.sr\n",
    "        if hop_length is None: hop_length=self.hop_length\n",
    "        if fmin is None: fmin=self.fmin\n",
    "        if n_bins is None: n_bins=self.n_bins\n",
    "        \n",
    "        C = librosa.cqt(audio_array, sr=sr, fmin=fmin, n_bins=n_bins, hop_length=hop_length)\n",
    "#         return C\n",
    "        if self.feature_to_extract is \"mean\": feature = C.mean(axis=0).mean(axis=0)\n",
    "        elif self.feature_to_extract is \"var\": feature = C.var()\n",
    "        else: feature = C.mean(axis=0).mean(axis=0)\n",
    "        return abs(feature)\n",
    "        \n",
    "    def get_chromagram(self, audio_array, sr=None, hop_length=None):\n",
    "        if sr is None: sr=self.sr\n",
    "        if hop_length is None: hop_length=self.hop_length\n",
    "            \n",
    "        chromagram = librosa.feature.chroma_cens(audio_array, sr=sr, hop_length=hop_length)\n",
    "#         return chromagram\n",
    "        if self.feature_to_extract is \"mean\": feature = chromagram.mean(axis=0).mean(axis=0)\n",
    "        elif self.feature_to_extract is \"var\": feature = chromagram.var()\n",
    "        else: feature = chromagram.mean(axis=0).mean(axis=0)\n",
    "        return feature\n",
    "\n",
    "    def get_spectral_contrast(self, audio_array, sr=None):\n",
    "        if sr is None: sr=self.sr\n",
    "            \n",
    "        spectral_contrast = librosa.feature.spectral_contrast(audio_array, sr=self.sr)\n",
    "#         return spectral_contrast\n",
    "        if self.feature_to_extract is \"mean\": feature = spectral_contrast.mean(axis=0).mean(axis=0)\n",
    "        elif self.feature_to_extract is \"var\": feature = spectral_contrast.var()\n",
    "        else: feature = spectral_contrast.mean(axis=0).mean(axis=0)\n",
    "        return feature\n",
    "\n",
    "    def get_autocorrelation(self, audio_array, sr=None, hop_length=None, lag_seconds=None):\n",
    "        if sr is None: sr=self.sr\n",
    "        if hop_length is None: hop_length=self.hop_length\n",
    "        if lag_seconds is None: lag_seconds=self.lag_seconds\n",
    "        \n",
    "        max_size = lag_seconds * sr / hop_length\n",
    "        autocorrelation = librosa.autocorrelate(audio_array, max_size)\n",
    "        \n",
    "        if self.feature_to_extract is \"mean\": feature = autocorrelation.mean(axis=0)\n",
    "        elif self.feature_to_extract is \"var\": feature = autocorrelation.var()\n",
    "        else: feature = autocorrelation.mean(axis=0)\n",
    "        return feature\n",
    "\n",
    "    # Function that obtain Short Time Fourier Transform from an audio samples array\n",
    "    def get_stft(self, audio_array, hop_length=None, frame_length=None):\n",
    "        if hop_length is None: hop_length=self.hop_length\n",
    "        if frame_length is None: frame_length=self.frame_length\n",
    "            \n",
    "        stft = librosa.stft(audio_array, n_fft=frame_length, hop_length=hop_length)\n",
    "        \n",
    "        if self.feature_to_extract is \"mean\": feature = stft.mean(axis=0).mean(axis=0)\n",
    "        elif self.feature_to_extract is \"var\": feature = stft.var()\n",
    "        else: feature = stft.mean(axis=0).mean(axis=0)\n",
    "        return abs(feature)\n",
    "    \n",
    "    def get_rolloff(self, audio_array, sr=None):\n",
    "        if sr is None: sr=self.sr\n",
    "        \n",
    "        spectral_rolloff = librosa.feature.spectral_rolloff(audio_array+0.01, sr=sr)\n",
    "        \n",
    "        if self.feature_to_extract is \"mean\": feature = spectral_rolloff.mean(axis=0).mean(axis=0)\n",
    "        elif self.feature_to_extract is \"var\": feature = spectral_rolloff.var()\n",
    "        else: feature = spectral_rolloff.mean(axis=0).mean(axis=0)\n",
    "        return feature\n",
    "\n",
    "    def get_spectral_centroid(self, audio_array, sr=None):\n",
    "        if sr is None: sr=self.sr\n",
    "        \n",
    "        spectral_centroids = librosa.feature.spectral_centroid(audio_array, sr=sr)\n",
    "        \n",
    "        if self.feature_to_extract is \"mean\": feature = spectral_centroids.mean(axis=0).mean(axis=0)\n",
    "        elif self.feature_to_extract is \"var\": feature = spectral_centroids.var()\n",
    "        else: feature = spectral_centroids.mean(axis=0).mean(axis=0)\n",
    "        return feature\n",
    "    \n",
    "    # Codigo de prueba \n",
    "    def GET_SHOW_spectogram(self, stft, sr=None, hop_length=None):\n",
    "        if sr is None: sr=self.sr\n",
    "        if hop_length is None: hop_length=self.hop_length\n",
    "            \n",
    "        S = librosa.amplitude_to_db(abs(stft))\n",
    "        librosa.display.specshow(S, sr=sr, hop_length=hop_length, x_axis='time', y_axis='linear')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a pandas data frame with features\n",
    "\n",
    "class MusicFeaturesDictCreator:\n",
    "    \"\"\"\n",
    "    Class aim to create a dictionary with music features, concatenate music feature dictionaries \n",
    "    and export a final dictionary to a pandas dataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, features_dictionary=None , number_mfccs=None):\n",
    "        if features_dictionary is not None:\n",
    "            self.features_dictionary = features_dictionary\n",
    "            self.features_dictionary_keys = list(self.features_dictionary.keys())\n",
    "        else:\n",
    "            self.features_dictionary = {\n",
    "                    'Genre': [],\n",
    "                    'Energy': [],\n",
    "                    'RMSE': [],\n",
    "                    'ZCR': [],\n",
    "                    'MFCCS': number_mfccs,\n",
    "                    'CQT': [],\n",
    "                    'Spectral_Contrast': [],\n",
    "                    'Chromagram':[],\n",
    "                    'Tempo':[],\n",
    "                    'Autocorrelation':[],\n",
    "                    'STFT':[],\n",
    "                    'Rolloff':[],\n",
    "                    'Spectral_Centroid':[],\n",
    "            }\n",
    "            self.features_dictionary_keys = list(self.features_dictionary.keys())\n",
    "            \n",
    "\n",
    "    def ampliate_features_dictionary(self, audios_list, label_name, features_extractor:FeaturesExtractor):\n",
    "        \"\"\"\n",
    "        Make an addition of features extracted from an audio list to the instance dictionary created in the intantiation of the class\n",
    "        \"\"\"\n",
    "        \n",
    "        for audio_array in audios_list:\n",
    "                \n",
    "            self.features_dictionary['Genre'].append(label_name)\n",
    "                \n",
    "            if len(self.features_dictionary_keys) > 1:\n",
    "                short_time_energy = features_extractor.get_short_time_energy(audio_array)\n",
    "                self.features_dictionary[self.features_dictionary_keys[1]].append(short_time_energy)\n",
    "                \n",
    "            if len(self.features_dictionary_keys) > 2:\n",
    "                rmse = features_extractor.get_rmse(audio_array)\n",
    "                self.features_dictionary[self.features_dictionary_keys[2]].append(rmse)\n",
    "                \n",
    "            if len(self.features_dictionary_keys) > 3:\n",
    "                zcr = features_extractor.get_zcr(audio_array)\n",
    "                self.features_dictionary[self.features_dictionary_keys[3]].append(zcr)\n",
    "            \n",
    "            if len(self.features_dictionary_keys) > 4:\n",
    "                number_mfccs = self.features_dictionary['MFCCS']\n",
    "                mfccs = features_extractor.get_mfccs_means(audio_array, number_mfccs)\n",
    "                print(mfccs)\n",
    "                print(mfccs.shape)\n",
    "                \n",
    "               # Initializion of mfccs keys if yet it not exist\n",
    "                if not 'MFCCS0' in self.features_dictionary:\n",
    "                    for i in range(0, len(mfccs)):\n",
    "                        self.features_dictionary['MFCCS'+str(i)] = []\n",
    "                        \n",
    "                for i in range(0, len(mfccs)):\n",
    "                    self.features_dictionary['MFCCS'+str(i)].append(mfccs[i])\n",
    "            \n",
    "            if len(self.features_dictionary_keys) > 5:\n",
    "                cqt = features_extractor.get_cqt(audio_array)\n",
    "                self.features_dictionary[self.features_dictionary_keys[5]].append(cqt)\n",
    "            \n",
    "            if len(self.features_dictionary_keys) > 6:\n",
    "                spectral_contrast = features_extractor.get_spectral_contrast(audio_array)\n",
    "                self.features_dictionary[self.features_dictionary_keys[6]].append(spectral_contrast)\n",
    "            \n",
    "            if len(self.features_dictionary_keys) > 7:\n",
    "                chromagram = features_extractor.get_chromagram(audio_array)\n",
    "                self.features_dictionary[self.features_dictionary_keys[7]].append(chromagram)\n",
    "            \n",
    "            if len(self.features_dictionary_keys) > 8:\n",
    "                tempo = librosa.beat.tempo(audio_array, sr=22050)[0]\n",
    "                self.features_dictionary[self.features_dictionary_keys[8]].append(tempo)\n",
    "            \n",
    "            if len(self.features_dictionary_keys) > 9:\n",
    "                autocorrelation = features_extractor.get_autocorrelation(audio_array)\n",
    "                self.features_dictionary[self.features_dictionary_keys[9]].append(autocorrelation)\n",
    "            \n",
    "            if len(self.features_dictionary_keys) > 10:\n",
    "                stft = features_extractor.get_stft(audio_array)\n",
    "                self.features_dictionary[self.features_dictionary_keys[10]].append(stft)\n",
    "            \n",
    "            if len(self.features_dictionary_keys) > 11:\n",
    "                rolloff = features_extractor.get_rolloff(audio_array)\n",
    "                self.features_dictionary[self.features_dictionary_keys[11]].append(rolloff)\n",
    "            \n",
    "            if len(self.features_dictionary_keys) > 12:\n",
    "                spectral_centroid = features_extractor.get_spectral_centroid(audio_array)\n",
    "                self.features_dictionary[self.features_dictionary_keys[12]].append(spectral_centroid)\n",
    "                \n",
    "        return self.features_dictionary\n",
    "    \n",
    "    def concatenate_mfccs_tags(tags_array, number_mfccs=13):\n",
    "        \"\"\"\n",
    "        Method that concatenate mffcs tags in a tags array\n",
    "        \"\"\"\n",
    "        tags_mfccs_columns = [\"\" for x in range(number_mfccs)]\n",
    "        mfccs_literal = 'MFCCS'\n",
    "        for i in range(0, number_mfccs):\n",
    "            tags_mfccs_columns[i] = 'MFCCS'+str(i)\n",
    "\n",
    "        tags_array = [*tags_array, *tags_mfccs_columns]\n",
    "        return tags_array\n",
    "    \n",
    "    def concatenate_features_arrays_dictionaries(self, dict_one, dict_two):\n",
    "    \n",
    "        dict_two_size = len(dict_two['Energy'])\n",
    "\n",
    "        for i in range(0, dict_two_size):\n",
    "            if 'Energy' in self.features_dictionary:\n",
    "                dict_one['Energy'].append(dict_two['Energy'][i])\n",
    "            \n",
    "            if 'RMSE' in self.features_dictionary:\n",
    "                dict_one['RMSE'].append(dict_two['RMSE'][i])\n",
    "            \n",
    "            if 'ZCR' in self.features_dictionary:\n",
    "                dict_one['ZCR'].append(dict_two['ZCR'][i])\n",
    "            \n",
    "            if 'MFCCS' in self.features_dictionary:\n",
    "                dict_one['MFCCS'].append(dict_two['MFCCS'][i])\n",
    "            \n",
    "            if 'CQT' in self.features_dictionary:\n",
    "                dict_one['CQT'].append(dict_two['CQT'][i])\n",
    "            \n",
    "            if 'Spectral_Contrast' in self.features_dictionary:\n",
    "                dict_one['Spectral_Contrast'].append(dict_two['Spectral_Contrast'][i])\n",
    "            \n",
    "            if 'Chromagram' in self.features_dictionary:\n",
    "                dict_one['Chromagram'].append(dict_two['Chromagram'][i])\n",
    "            \n",
    "            if 'Tempo' in self.features_dictionary:\n",
    "                dict_one['Tempo'].append(dict_two['Tempo'][i])\n",
    "            \n",
    "            if 'Autocorrelation' in self.features_dictionary:\n",
    "                dict_one['Autocorrelation'].append(dict_two['Autocorrelation'][i])\n",
    "                \n",
    "            if 'STFT' in self.features_dictionary:\n",
    "                dict_one['STFT'].append(dict_two['STFT'][i])\n",
    "            \n",
    "            if 'Rolloff' in self.features_dictionary:\n",
    "                dict_one['Rolloff'].append(dict_two['Rolloff'][i])\n",
    "            \n",
    "            if 'Spectral_Centroid' in self.features_dictionary:\n",
    "                dict_one['Spectral_Centroid'].append(dict_two['Spectral_Centroid'][i])\n",
    "            \n",
    "        return dict_one\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'audios_classical' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1636/2657878395.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[1;31m# Export pandas dataFrame in a csv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_extraction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ismir04_100.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1636/2657878395.py\u001b[0m in \u001b[0;36mdf_extraction\u001b[1;34m()\u001b[0m\n\u001b[0;32m    110\u001b[0m     \"\"\"\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m     \u001b[0mfeatures_array_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmultiprocess_feature_dict_creation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1636/2657878395.py\u001b[0m in \u001b[0;36mmultiprocess_feature_dict_creation\u001b[1;34m()\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;31m# ISMIR04\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m     \u001b[0mmean_features_array_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_feature_dict_creator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mampliate_features_dictionary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maudios_classical\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Classical'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_features_extractor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m     \u001b[0mmean_features_array_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_feature_dict_creator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mampliate_features_dictionary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maudios_electronic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Electronic'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_features_extractor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[0mmean_features_array_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_feature_dict_creator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mampliate_features_dictionary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maudios_jazz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Jazz'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_features_extractor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'audios_classical' is not defined"
     ]
    }
   ],
   "source": [
    "def multiprocess_feature_dict_creation():\n",
    "    \n",
    "    mean_features_extractor = FeaturesExtractor(feature_to_extract=\"mean\")\n",
    "    var_features_extractor = FeaturesExtractor(feature_to_extract=\"var\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    mean_features_dictionary = {\n",
    "                    'Genre': [],\n",
    "                    'Energy_Mean': [],\n",
    "                    'RMSE_Mean': [],\n",
    "                    'ZCR_Mean': [],\n",
    "                    'MFCCS': 13,\n",
    "                    'CQT_Mean': [],\n",
    "                    'Spectral_Contrast_Mean': [],\n",
    "                    'Chromagram_Mean':[],\n",
    "                    'Tempo_Mean':[],\n",
    "                    'Autocorrelation_Mean':[],\n",
    "                    'STFT_Mean':[],\n",
    "                    'Rolloff_Mean':[],\n",
    "                    'Spectral_Centroid_Mean':[],\n",
    "    }\n",
    "    \n",
    "    var_features_dictionary = {\n",
    "                    'Genre': [],\n",
    "                    'Energy_Var': [],\n",
    "                    'RMSE_Var': [],\n",
    "                    'ZCR_Var': [],\n",
    "                    'MFCCS': 13,\n",
    "                    'CQT_Var': [],\n",
    "                    'Spectral_Contrast_Var': [],\n",
    "                    'Chromagram_Var':[],\n",
    "                    'Tempo_Var':[],\n",
    "                    'Autocorrelation_Var':[],\n",
    "                    'STFT_Var':[],\n",
    "                    'Rolloff_Var':[],\n",
    "                    'Spectral_Centroid_Var':[],\n",
    "    }\n",
    "    \n",
    "    mean_feature_dict_creator = MusicFeaturesDictCreator(mean_features_dictionary)\n",
    "    var_feature_dict_creator = MusicFeaturesDictCreator(var_features_dictionary)\n",
    "    \n",
    "#     LINES USED FOR TESTING RUNNING EXCEPTIONS USING LESS DATA\n",
    "    \n",
    "#     mean_features_array_dict = mean_feature_dict_creator.ampliate_features_dictionary(audios_blues[:2], 'Blues', mean_features_extractor) # Initializing\n",
    "#     mean_features_array_dict = mean_feature_dict_creator.ampliate_features_dictionary(audios_classical[:2], 'Classical', mean_features_extractor)\n",
    "    \n",
    "#     var_features_array_dict = var_feature_dict_creator.ampliate_features_dictionary(audios_blues[:2], 'Blues', var_features_extractor) # Initializing\n",
    "#     var_features_array_dict = var_feature_dict_creator.ampliate_features_dictionary(audios_classical[:2], 'Classical', var_features_extractor)\n",
    "    \n",
    "#     features_array_dict = {**mean_features_array_dict, **var_features_array_dict}\n",
    "    \n",
    "    \n",
    "#     GTZAN\n",
    "    \n",
    "    \n",
    "#     mean_features_array_dict = mean_feature_dict_creator.ampliate_features_dictionary(audios_blues, 'Blues', mean_features_extractor) # Initializing\n",
    "#     mean_features_array_dict = mean_feature_dict_creator.ampliate_features_dictionary(audios_classical, 'Classical', mean_features_extractor)\n",
    "#     mean_features_array_dict = mean_feature_dict_creator.ampliate_features_dictionary(audios_country, 'Country', mean_features_extractor)\n",
    "#     mean_features_array_dict = mean_feature_dict_creator.ampliate_features_dictionary(audios_disco, 'Disco', mean_features_extractor)\n",
    "#     mean_features_array_dict = mean_feature_dict_creator.ampliate_features_dictionary(audios_hiphop, 'Hiphop', mean_features_extractor)\n",
    "#     mean_features_array_dict = mean_feature_dict_creator.ampliate_features_dictionary(audios_jazz, 'Jazz', mean_features_extractor)\n",
    "#     mean_features_array_dict = mean_feature_dict_creator.ampliate_features_dictionary(audios_metal, 'Metal', mean_features_extractor)\n",
    "#     mean_features_array_dict = mean_feature_dict_creator.ampliate_features_dictionary(audios_pop, 'Pop', mean_features_extractor)\n",
    "#     mean_features_array_dict = mean_feature_dict_creator.ampliate_features_dictionary(audios_reggae, 'Reggae', mean_features_extractor)\n",
    "#     mean_features_array_dict = mean_feature_dict_creator.ampliate_features_dictionary(audios_rock, 'Rock', mean_features_extractor)\n",
    "    \n",
    "#     var_features_array_dict = var_feature_dict_creator.ampliate_features_dictionary(audios_blues, 'Blues', var_features_extractor) # Initializing\n",
    "#     var_features_array_dict = var_feature_dict_creator.ampliate_features_dictionary(audios_classical, 'Classical', var_features_extractor)\n",
    "#     var_features_array_dict = var_feature_dict_creator.ampliate_features_dictionary(audios_country, 'Country', var_features_extractor)\n",
    "#     var_features_array_dict = var_feature_dict_creator.ampliate_features_dictionary(audios_disco, 'Disco', var_features_extractor)\n",
    "#     var_features_array_dict = var_feature_dict_creator.ampliate_features_dictionary(audios_hiphop, 'Hiphop', var_features_extractor)\n",
    "#     var_features_array_dict = var_feature_dict_creator.ampliate_features_dictionary(audios_jazz, 'Jazz', var_features_extractor)\n",
    "#     var_features_array_dict = var_feature_dict_creator.ampliate_features_dictionary(audios_metal, 'Metal', var_features_extractor)\n",
    "#     var_features_array_dict = var_feature_dict_creator.ampliate_features_dictionary(audios_pop, 'Pop', var_features_extractor)\n",
    "#     var_features_array_dict = var_feature_dict_creator.ampliate_features_dictionary(audios_reggae, 'Reggae', var_features_extractor)\n",
    "#     var_features_array_dict = var_feature_dict_creator.ampliate_features_dictionary(audios_rock, 'Rock', var_features_extractor)\n",
    "\n",
    "\n",
    "# ISMIR04\n",
    "\n",
    "    mean_features_array_dict = mean_feature_dict_creator.ampliate_features_dictionary(audios_classical, 'Classical', mean_features_extractor)\n",
    "    mean_features_array_dict = mean_feature_dict_creator.ampliate_features_dictionary(audios_electronic, 'Electronic', mean_features_extractor)\n",
    "    mean_features_array_dict = mean_feature_dict_creator.ampliate_features_dictionary(audios_jazz, 'Jazz', mean_features_extractor)\n",
    "    mean_features_array_dict = mean_feature_dict_creator.ampliate_features_dictionary(audios_metal, 'Metal', mean_features_extractor)\n",
    "    mean_features_array_dict = mean_feature_dict_creator.ampliate_features_dictionary(audios_pop, 'Pop', mean_features_extractor)\n",
    "    mean_features_array_dict = mean_feature_dict_creator.ampliate_features_dictionary(audios_punk, 'Punk', mean_features_extractor)\n",
    "    mean_features_array_dict = mean_feature_dict_creator.ampliate_features_dictionary(audios_rock, 'Rock', mean_features_extractor)\n",
    "    mean_features_array_dict = mean_feature_dict_creator.ampliate_features_dictionary(audios_world, 'World', mean_features_extractor)\n",
    "\n",
    "    var_features_array_dict = var_feature_dict_creator.ampliate_features_dictionary(audios_classical, 'Classical', var_features_extractor)\n",
    "    var_features_array_dict = var_feature_dict_creator.ampliate_features_dictionary(audios_electronic, 'Electronic', var_features_extractor)\n",
    "    var_features_array_dict = var_feature_dict_creator.ampliate_features_dictionary(audios_jazz, 'Jazz', var_features_extractor)\n",
    "    var_features_array_dict = var_feature_dict_creator.ampliate_features_dictionary(audios_metal, 'Metal', var_features_extractor)\n",
    "    var_features_array_dict = var_feature_dict_creator.ampliate_features_dictionary(audios_pop, 'Pop', var_features_extractor)\n",
    "    var_features_array_dict = var_feature_dict_creator.ampliate_features_dictionary(audios_punk, 'Punk', var_features_extractor)\n",
    "    var_features_array_dict = var_feature_dict_creator.ampliate_features_dictionary(audios_rock, 'Rock', var_features_extractor)\n",
    "    var_features_array_dict = var_feature_dict_creator.ampliate_features_dictionary(audios_world, 'World', var_features_extractor)\n",
    "\n",
    "\n",
    "    features_array_dict = {**mean_features_array_dict, **var_features_array_dict}\n",
    "#     features_array_dict = mean_features_array_dict\n",
    "#     features_array_dict = var_features_array_dict\n",
    "\n",
    "    return features_array_dict\n",
    "\n",
    "def df_extraction():\n",
    "    \"\"\"\n",
    "    Method that convert a features dictionary in a pandas dataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    features_array_dict = multiprocess_feature_dict_creation()\n",
    "    \n",
    "    \n",
    "#     tags_dataframe_columns = ['Genre', 'Energy_Mean', 'RMSE_Mean', 'ZCR_Mean', 'CQT_Mean', 'Spectral_Contrast_Mean', 'Chromagram_Mean', 'Tempo_Mean', 'STFT_Mean', \n",
    "#                               'Autocorrelation_Mean', 'STFT_Mean', 'Spectral_Centroid_Mean', 'Rolloff_Mean']\n",
    "    \n",
    "    tags_dataframe_columns = ['Genre', 'Energy_Mean', 'RMSE_Mean', 'ZCR_Mean', 'CQT_Mean', 'Spectral_Contrast_Mean', 'Chromagram_Mean', 'Tempo_Mean', 'STFT_Mean', \n",
    "                              'Autocorrelation_Mean', 'STFT_Mean', 'Spectral_Centroid_Mean', 'Rolloff_Mean',\n",
    "                              'Energy_Var', 'RMSE_Var', 'ZCR_Var', 'CQT_Var', 'Spectral_Contrast_Var', 'Chromagram_Var', 'Tempo_Var', 'STFT_Var',\n",
    "                              'Autocorrelation_Var', 'STFT_Var', 'Spectral_Centroid_Var', 'Rolloff_Var']\n",
    "    \n",
    "    tags_dataframe_columns = MusicFeaturesDictCreator.concatenate_mfccs_tags(tags_dataframe_columns)\n",
    "    print(tags_dataframe_columns)\n",
    "#     tags_dataframe_columns = ['Genre', 'Energy', 'RMSE', 'ZCR', 'CQT', 'Spectral_Contrast', 'Chromagram', 'Tempo', 'MFCCS']\n",
    "    \n",
    "    print(features_array_dict)\n",
    "    \n",
    "    df = pd.DataFrame(features_array_dict, columns = tags_dataframe_columns)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Export pandas dataFrame in a csv\n",
    "\n",
    "df = df_extraction()\n",
    "\n",
    "df.to_csv('ismir04_100.csv')\n",
    "\n",
    "\n",
    "print(df.head(5))\n",
    "print('impresito')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Genre': [], 'Energy': [], 'RMSE': [], 'ZCR': [], 'MFCCS': None, 'CQT': [], 'Spectral_Contrast': [], 'Chromagram': [], 'Tempo': [], 'Autocorrelation': [], 'STFT': [], 'Rolloff': [], 'Spectral_Centroid': []}\n"
     ]
    }
   ],
   "source": [
    " feature_dict_creator = MusicFeaturesDictCreator()\n",
    "    \n",
    "print(feature_dict_creator.features_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Datasets.fma.fma import utils\n",
    "tracks = utils.load('Datasets/fma/fma/data/fma_metadata/tracks.csv')\n",
    "features = utils.load('Datasets/fma/fma/data/fma_metadata/features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Genre', 'ZCR_Mean', 'RMSE_Mean', 'MFCCS0', 'MFCCS1', 'MFCCS2', 'MFCCS3', 'MFCCS4', 'MFCCS5', 'MFCCS6', 'MFCCS7', 'MFCCS8', 'MFCCS9', 'MFCCS10', 'MFCCS11', 'MFCCS12']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>ZCR_Mean</th>\n",
       "      <th>RMSE_Mean</th>\n",
       "      <th>MFCCS0</th>\n",
       "      <th>MFCCS1</th>\n",
       "      <th>MFCCS2</th>\n",
       "      <th>MFCCS3</th>\n",
       "      <th>MFCCS4</th>\n",
       "      <th>MFCCS5</th>\n",
       "      <th>MFCCS6</th>\n",
       "      <th>MFCCS7</th>\n",
       "      <th>MFCCS8</th>\n",
       "      <th>MFCCS9</th>\n",
       "      <th>MFCCS10</th>\n",
       "      <th>MFCCS11</th>\n",
       "      <th>MFCCS12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>0.085629</td>\n",
       "      <td>3.188761</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-163.772964</td>\n",
       "      <td>116.696678</td>\n",
       "      <td>-41.753826</td>\n",
       "      <td>29.144329</td>\n",
       "      <td>-15.050158</td>\n",
       "      <td>18.879372</td>\n",
       "      <td>-8.918165</td>\n",
       "      <td>12.002118</td>\n",
       "      <td>-4.253151</td>\n",
       "      <td>1.359791</td>\n",
       "      <td>-2.683000</td>\n",
       "      <td>-0.794632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>0.053114</td>\n",
       "      <td>3.251386</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-205.440491</td>\n",
       "      <td>132.215073</td>\n",
       "      <td>-16.085823</td>\n",
       "      <td>41.514759</td>\n",
       "      <td>-7.642954</td>\n",
       "      <td>16.942802</td>\n",
       "      <td>-5.651261</td>\n",
       "      <td>9.569445</td>\n",
       "      <td>0.503157</td>\n",
       "      <td>8.673513</td>\n",
       "      <td>-8.271377</td>\n",
       "      <td>0.594473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pop</td>\n",
       "      <td>0.077515</td>\n",
       "      <td>3.893810</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-135.864822</td>\n",
       "      <td>157.040085</td>\n",
       "      <td>-53.453247</td>\n",
       "      <td>17.198896</td>\n",
       "      <td>6.868035</td>\n",
       "      <td>13.934344</td>\n",
       "      <td>-11.749298</td>\n",
       "      <td>8.360711</td>\n",
       "      <td>-5.130381</td>\n",
       "      <td>0.233845</td>\n",
       "      <td>-5.421206</td>\n",
       "      <td>1.679479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Folk</td>\n",
       "      <td>0.052379</td>\n",
       "      <td>2.953848</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-225.713318</td>\n",
       "      <td>139.332825</td>\n",
       "      <td>-13.097699</td>\n",
       "      <td>44.533356</td>\n",
       "      <td>2.468400</td>\n",
       "      <td>28.328743</td>\n",
       "      <td>-9.931481</td>\n",
       "      <td>10.810857</td>\n",
       "      <td>3.002879</td>\n",
       "      <td>-0.937692</td>\n",
       "      <td>7.138268</td>\n",
       "      <td>-6.625260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Folk</td>\n",
       "      <td>0.040267</td>\n",
       "      <td>2.576761</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-253.143906</td>\n",
       "      <td>155.716324</td>\n",
       "      <td>-16.636627</td>\n",
       "      <td>23.683815</td>\n",
       "      <td>6.045957</td>\n",
       "      <td>11.692952</td>\n",
       "      <td>-9.947761</td>\n",
       "      <td>6.887814</td>\n",
       "      <td>-3.273322</td>\n",
       "      <td>-6.340906</td>\n",
       "      <td>7.602782</td>\n",
       "      <td>-5.851329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Genre  ZCR_Mean  RMSE_Mean MFCCS0      MFCCS1      MFCCS2     MFCCS3  \\\n",
       "0  Hip-Hop  0.085629   3.188761    NaN -163.772964  116.696678 -41.753826   \n",
       "1  Hip-Hop  0.053114   3.251386    NaN -205.440491  132.215073 -16.085823   \n",
       "2      Pop  0.077515   3.893810    NaN -135.864822  157.040085 -53.453247   \n",
       "3     Folk  0.052379   2.953848    NaN -225.713318  139.332825 -13.097699   \n",
       "4     Folk  0.040267   2.576761    NaN -253.143906  155.716324 -16.636627   \n",
       "\n",
       "      MFCCS4     MFCCS5     MFCCS6     MFCCS7     MFCCS8    MFCCS9   MFCCS10  \\\n",
       "0  29.144329 -15.050158  18.879372  -8.918165  12.002118 -4.253151  1.359791   \n",
       "1  41.514759  -7.642954  16.942802  -5.651261   9.569445  0.503157  8.673513   \n",
       "2  17.198896   6.868035  13.934344 -11.749298   8.360711 -5.130381  0.233845   \n",
       "3  44.533356   2.468400  28.328743  -9.931481  10.810857  3.002879 -0.937692   \n",
       "4  23.683815   6.045957  11.692952  -9.947761   6.887814 -3.273322 -6.340906   \n",
       "\n",
       "    MFCCS11   MFCCS12  \n",
       "0 -2.683000 -0.794632  \n",
       "1 -8.271377  0.594473  \n",
       "2 -5.421206  1.679479  \n",
       "3  7.138268 -6.625260  \n",
       "4  7.602782 -5.851329  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FMA dataframe extractor\n",
    "\n",
    "fma_features_dictionary = {\n",
    "    'Genre': [],\n",
    "    'Energy_Mean': [],\n",
    "    'RMSE_Mean': [],\n",
    "    'ZCR_Mean': [],\n",
    "    'MFCCS': 13,\n",
    "    'CQT_Mean': [],\n",
    "    'Spectral_Contrast_Mean': [],\n",
    "    'Chromagram_Mean':[],\n",
    "    'Tempo_Mean':[],\n",
    "    'Autocorrelation_Mean':[],\n",
    "    'STFT_Mean':[],\n",
    "    'Rolloff_Mean':[],\n",
    "    'Spectral_Centroid_Mean':[],\n",
    "}\n",
    "\n",
    "fma_features_dictionary = {\n",
    "    'Genre': [],\n",
    "    'ZCR_Mean': [],\n",
    "    'RMSE_Mean': [],\n",
    "}\n",
    "\n",
    "# FMA feature extraction\n",
    "\n",
    "small = tracks['set', 'subset'] <= 'small'\n",
    "\n",
    "# instrumental = tracks['track', 'genre_top'] == 'Instrumental'\n",
    "# rock = tracks['track', 'genre_top'] == 'Rock'\n",
    "# classical = tracks['track', 'genre_top'] == 'classical'\n",
    "# country = tracks['track', 'genre_top'] == 'country'\n",
    "\n",
    "def fma_mfccs_means_to_my_dict_converter(features_dict, mfccs_means):\n",
    "    number_mfccs = 13\n",
    "    for i in range(1, number_mfccs):\n",
    "        features_dict['MFCCS'+str(i)] = []\n",
    "\n",
    "    for j in range(1, number_mfccs):\n",
    "        if j < 10:\n",
    "            features_dict['MFCCS'+str(j)] = mfccs_means['0'+str(j)].to_list()\n",
    "        else:\n",
    "            features_dict['MFCCS'+str(j)] = mfccs_means[str(j)].to_list()\n",
    "    return features_dict\n",
    "\n",
    "mfccs_means  = features.loc[small, 'mfcc']['mean']\n",
    "fma_mfccs_means_to_my_dict_converter(fma_features_dictionary, mfccs_means)\n",
    "\n",
    "zcr_means  = features.loc[small, 'zcr']['mean']['01'].to_list()\n",
    "fma_features_dictionary['ZCR_Mean'] = zcr_means\n",
    "\n",
    "rmse_means  = features.loc[small, 'rmse']['mean']['01'].to_list()\n",
    "fma_features_dictionary['RMSE_Mean'] = rmse_means\n",
    "\n",
    "genres = tracks.loc[small, ('track', 'genre_top')].to_list()\n",
    "fma_features_dictionary['Genre'] = genres\n",
    "\n",
    "tags_dataframe_columns = ['Genre', 'ZCR_Mean', 'RMSE_Mean']\n",
    "\n",
    "def simple_df_creator(fma_features_dictionary, tags_dataframe_columns):\n",
    "    tags_dataframe_columns = MusicFeaturesDictCreator.concatenate_mfccs_tags(tags_dataframe_columns)\n",
    "    \n",
    "    print(tags_dataframe_columns)\n",
    "    \n",
    "    df = pd.DataFrame(fma_features_dictionary, columns = tags_dataframe_columns)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "df = simple_df_creator(fma_features_dictionary, tags_dataframe_columns)\n",
    "\n",
    "df.to_csv('rmse.csv')\n",
    "\n",
    "df.head(5)\n",
    "\n",
    "# genres = utils.load('Datasets/fma/fma/data/fma_metadata/genres.csv')\n",
    "# print('{} top-level genres'.format(len(genres['top_level'].unique())))\n",
    "# genres.loc[genres['top_level'].unique()].sort_values('#tracks', ascending=False)\n",
    "\n",
    "# train = tracks['set', 'split'] == 'training'\n",
    "# val = tracks['set', 'split'] == 'validation'\n",
    "# test = tracks['set', 'split'] == 'test'\n",
    "\n",
    "# X_train = features.loc[small & train, 'zcr']\n",
    "# Y_train = tracks.loc[small & train, ('track', 'genre_top')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
